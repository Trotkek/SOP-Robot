import math
import sys
import time
import random

import rclpy
from rclpy.action import ActionClient
from rclpy.node import Node

from control_msgs.action import FollowJointTrajectory
from control_msgs.msg import JointTrajectoryControllerState
from trajectory_msgs.msg import JointTrajectory, JointTrajectoryPoint
from builtin_interfaces.msg import Duration
from face_tracker_msgs.msg import Point2, Faces


class FaceTrackerMovementNode(Node):

    def __init__(self, functionality):
        super().__init__('face_tracker_movement_client')

        # Action clients for eye and head controllers
        self.eye_action_client = ActionClient(self, FollowJointTrajectory, '/eyes_controller/follow_joint_trajectory')
        self.head_action_client = ActionClient(self, FollowJointTrajectory, '/head_controller/follow_joint_trajectory')

        # ROS2 subscriptions
        self.face_subscription = self.create_subscription(Point2, '/face_tracker/face_location_topic', self.listener_callback, 1)
        self.face_list_subscription = self.create_subscription(Faces, '/face_tracker/face_topic', self.face_list_callback, 2)
        self.head_state_subscription = self.create_subscription(JointTrajectoryControllerState, '/head_controller/state', self.head_state_callback, 5)
        self.eyes_state_subscription = self.create_subscription(JointTrajectoryControllerState, '/eyes_controller/state', self.eyes_state_callback, 5)

        # Middle point of image view
        self.middle_x = 640
        self.middle_y = 400
        self.is_glancing = False
        self.idling = False # Not used currently

        self.head_joint_ids = [4, 1, 3, 2]              # Servo ids for head joints. Order comes from head_controller: [head_pan_joint, head_tilt_right_joint, head_tilt_left_joint, head_tilt_vertical_joint]
        self.start_head_state = [0.6, 0.5, -0.5, 1.2]   # Good starting values for head servos. Should not be modified in runtime.
        self.head_state = self.start_head_state[:]      # Tries to have the up-to-date head servo values.

        self.eyes_joint_ids = [9, 11]                   # Servo ids for eye joints. Order comes from eyes_controller: [eyes_shift_horizontal_joint, eyes_shift_vertical_joint]
        self.start_eyes_state = [-0.7, -0.75]           # Good starting values for eye servos. Should not be modified in runtime.
        self.eyes_state = self.start_eyes_state[:]      # Tries to have the up-to-date head servo values.

        # Some variables
        self.pan_diff = 0
        self.goal_pan = self.head_state[0]
        self.v_diff = 0
        self.goal_vertical_tilt = self.head_state[3]

        # Are head/eye joints used in the current configuration? 
        self.head_enabled = True
        self.eyes_enabled = True
        self.visible_face_amount = 0

        if functionality.lower() == "head":
            self.get_logger().info('Eye movement is disabled.')
            self.eyes_enabled = False
        elif functionality.lower() == "eyes":
            self.get_logger().info('Head movement is disabled.')
            self.head_enabled = False

        self.center_eyes()
        self.send_head_goal(self.head_state[0], self.head_state[3], self.head_state[1])
        time.sleep(1)

        self.idle_timer = self.create_timer(5, self.idle_timer_callback)

        self.get_logger().info('Face tracking movement client initialized.')

    # Get the amount of detected faces
    def face_list_callback(self, msg):
        #self.get_logger().info(str(msg))
        self.visible_face_amount = len(msg.faces)
        
    # Get the current state of head joints. Updated at 20 Hz (see robot.yaml)
    def head_state_callback(self, msg):
        for i, val in enumerate(msg.actual.positions):
            if math.isnan(val):
                self.head_state[i] = self.start_head_state[i]
                self.get_logger().info("Head joint ID " + str(self.head_joint_ids[i]) + " is not responding")
            else:
                self.head_state[i] = val

    # Get the current state of eye joints. Updated at 20 Hz (see robot.yaml)
    def eyes_state_callback(self, msg):
        for i, val in enumerate(msg.actual.positions):
            if math.isnan(val):
                self.eyes_state[i] = self.start_eyes_state[i]
                self.get_logger().info("Eye joint ID " + str(self.eyes_joint_ids[i]) + " is not responding")
            else:
                self.eyes_state[i] = val

    # Get random horizontal positions for eyes and head and turn there at a random speed
    def idle_timer_callback(self):
        self.idling = True
        self.get_logger().info("Idling...\x1B[1A")
        self.send_eye_goal(self.get_random_eye_location()[0], -0.75)
        self.goal_pan = random.uniform(0.25, 1.25)
        self.send_pan_and_vertical_tilt_goal(self.goal_pan, self.start_head_state[3], Duration(sec=0, nanosec= random.randint(1000000000, 4000000000)))
        self.idle_timer.timer_period_ns = random.randint(1000000000, 4000000000)
        self.idle_timer.reset()
        
    # Main loop. Excecuted when face_tracker_node publishes face coordinates.
    def listener_callback(self, msg):
        self.idle_timer.timer_period_ns = 5000000000
        self.idle_timer.reset()
        self.idling = False

        if self.eyes_enabled:
            #self.get_logger().info('x: %d, y: %d' % (msg.x, msg.y))
            glance_percentage = 0.005 # Chance of executing a glance on each frame where a face has been detected. TODO: Decide on a good value
            randomvalue = random.uniform(0, 1)  

            # Check if doing the glance or not
            if randomvalue <= glance_percentage:
                eye_location_x, eye_location_y = self.get_random_eye_location()
                self.is_glancing = True
                self.get_logger().info('glance')
            else:
                eye_location_x, eye_location_y = self.transform_face_location_to_eye_location(msg.x, msg.y)
                self.is_glancing = False

            # Move eyes
            self.send_eye_goal(eye_location_x, eye_location_y)

            if self.is_glancing:
                # Center the eyes back to the face after glancing
                time.sleep(0.5)
                self.center_eyes()
                time.sleep(0.7)
                return
        
        if self.head_enabled:
            self.goal_pan, self.goal_vertical_tilt = self.transform_face_location_to_head_values(msg.x, msg.y)
            self.pan_diff = self.goal_pan - self.head_state[0]
            self.v_diff = self.goal_vertical_tilt - self.head_state[3]
            if self.pan_diff != 0 or self.v_diff != 0: 
                self.get_logger().info("Turning head to x: " + str(self.goal_pan) + " y: " + str(self.goal_vertical_tilt))
                self.send_pan_and_vertical_tilt_goal(self.goal_pan, self.goal_vertical_tilt)
                time.sleep(0.3)
        
        time.sleep(0.2)

    def send_eye_goal(self, horizontal, vertical, duration=None):
        # The eyes lock up if they try to move too fast so it'll go a bit slower for longer movements (also faster for short movements)
        if duration == None:
            x_diff = abs(self.eyes_state[0] - horizontal)
            duration = Duration(sec=0, nanosec=max(int(200000000 * x_diff), 200000000))

        goal_msg = FollowJointTrajectory.Goal()
        trajectory_points = JointTrajectoryPoint(positions=[horizontal, vertical], time_from_start=duration)
        goal_msg.trajectory = JointTrajectory(joint_names=['eyes_shift_horizontal_joint', 'eyes_shift_vertical_joint'],
                                              points=[trajectory_points])

        self.eye_action_client.wait_for_server()

        self.eye_action_client.send_goal_async(goal_msg)
        #self.get_logger().info('eye location x: %f, eye location y: %f' % (horizontal, vertical))

    def send_horizontal_tilt_goal(self, horizontalTilt):
        goal_msg = FollowJointTrajectory.Goal()
        trajectory_points = JointTrajectoryPoint(positions=[-horizontalTilt, horizontalTilt], time_from_start=Duration(sec=1, nanosec=0))
        goal_msg.trajectory = JointTrajectory(joint_names=['head_tilt_left_joint', 'head_tilt_right_joint'],
                                              points=[trajectory_points])
        
        self.head_action_client.wait_for_server()

        self.head_action_client.send_goal_async(goal_msg)
        
    def send_pan_and_vertical_tilt_goal(self, pan, verticalTilt, duration=Duration(sec=0, nanosec=400000000)):
        goal_msg = FollowJointTrajectory.Goal()
        trajectory_points = JointTrajectoryPoint(positions=[pan, verticalTilt], time_from_start=duration)
        goal_msg.trajectory = JointTrajectory(joint_names=['head_pan_joint', 'head_tilt_vertical_joint'],
                                              points=[trajectory_points])

        self.head_action_client.wait_for_server()

        self.head_action_client.send_goal_async(goal_msg)

    # Horizontal tilt is done separately and slower because the joints easily get stuck when moving quickly.
    def send_head_goal(self, pan, verticalTilt, horizontalTilt):
        #self.send_horizontal_tilt_goal(horizontalTilt) TODO: UNCOMMENT WHEN MECHANISM HAS BEEN MADE FUNCTIONAL AGAIN
        #time.sleep(1) # Wait a bit so that the new goal doesn't override the old, still-in-process goal
        self.send_pan_and_vertical_tilt_goal(pan, verticalTilt)

    """
    Calculates new pan and vertical tilt values corresponding to the face location coordinates given
    as arguments. 

    Returns: Absolute pan and vertical tilt values for head servos
    """
    def transform_face_location_to_head_values(self, face_location_x, face_location_y):
       
        # Calculate face movement
        x_diff = self.middle_x - face_location_x
        y_diff = self.middle_y - face_location_y

        # If the face is close enough to the center, leave the small movements for the eyes.
        if abs(x_diff) < 100:
            x_diff = 0
        if abs(y_diff) < 50:
            y_diff = 0

        # Transform face movement to head joint values
        # Head pan
        h_coeff = -0.00078

        """
        When eyes are used for movement, do not move head when there are multiple faces detected.
        Done to mitigate robot going back and forth between detected faces when they are roughly at the same distance.
        """
        if self.visible_face_amount > 1 and self.eyes_enabled:
            h_coeff = 0

        pan = x_diff * h_coeff + self.head_state[0]
        pan = max(min(1.75, pan), -0.25) # limit head values to reasonable values
        # Alternative version: Adjust the pan value slightly to make smaller movements a bit bigger
        #pan = 0.8 * abs(x_diff * h_coeff) ** 0.8
        #pan = math.copysign(pan, -x_diff)

        # Vertical tilt
        v_coeff = -0.002
        vertical_tilt = y_diff * v_coeff + self.head_state[3]
        vertical_tilt = max(min(1.5, vertical_tilt), 0.8)

        return pan, vertical_tilt

    """
    Calculates new x and y location for the eyes corresponding to the face location coordinates given
    as arguments.
    """
    def transform_face_location_to_eye_location(self, face_location_x, face_location_y):
        
        # Calculate face movement
        x_diff = self.middle_x - face_location_x
        y_diff = self.middle_y - face_location_y

        # Transform face movement to eye movement
        # Horizontal eye movement
        h_coeff = -0.002
        eye_location_x = x_diff * h_coeff + self.eyes_state[0]
        # Vertical eye movement
        v_coeff = 0.003
        eye_location_y = y_diff * v_coeff + self.eyes_state[1]
        
        eye_location_y = max(min(-0.2, eye_location_y), -0.7)

        return eye_location_x, eye_location_y

    #   Center eyes
    def center_eyes(self, duration=None):
        self.send_eye_goal(-0.7, -0.75, duration)


    """
    Returns a random location coordinates which is far enough from the current state of the eyes to be called a glance.
    """
    def get_random_eye_location(self):
        random_x = random.uniform(-2, 0.5)
        random_y = random.uniform(-1.5, 0)

        # Can possibly loop for a while because of the random number being too close multiple times but it should only rarely affect performance
        while abs(self.eyes_state[0] - random_x) < 0.5:
            random_x = random.uniform(-2, 0.5)

        return random_x, random_y


def main():
    print('Hi from face_tracker_movement.')

    rclpy.init()

    arg = "full"

    if len(sys.argv) > 1:
        arg = sys.argv[1]

    action_client = FaceTrackerMovementNode(arg)

    rclpy.spin(action_client)

    # Shutdown
    action_client.destroy_node()
    rclpy.shutdown()


if __name__ == '__main__':
    main()
